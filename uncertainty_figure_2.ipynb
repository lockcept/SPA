{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55185993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"src\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c489f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "env_list = [\n",
    "        \"button-press-topdown-v2\",\n",
    "        \"box-close-v2\",\n",
    "        \"dial-turn-v2\",\n",
    "        \"sweep-v2\",\n",
    "        \"button-press-topdown-wall-v2\",\n",
    "        \"sweep-into-v2\",\n",
    "        \"drawer-open-v2\",\n",
    "        \"lever-pull-v2\",\n",
    "]\n",
    "\n",
    "pair_algo = \"ternary-500\"\n",
    "reward_model_algo = \"MR-linear\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "TRAJECTORY_LENGTH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52e5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation.data_research import predict_rewards\n",
    "from data_loading.load_data import load_dataset\n",
    "\n",
    "\n",
    "def predict_only_rewards(\n",
    "    env_name,\n",
    "    exp_name,\n",
    "    pair_algo,\n",
    "    reward_model_algo,\n",
    "):\n",
    "    result = predict_rewards(\n",
    "        env_name=env_name,\n",
    "        exp_name=exp_name,\n",
    "        pair_algo=pair_algo,\n",
    "        reward_model_algo=reward_model_algo,\n",
    "    )\n",
    "\n",
    "    pred_reward_list = [r for (_, r, _, _) in result]\n",
    "    pred_reward_list = np.array(pred_reward_list)\n",
    "\n",
    "    return pred_reward_list\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def get_total_reward(s, e, reward_cumsum):\n",
    "    return reward_cumsum[e - 1] - (reward_cumsum[s - 1] if s > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1466c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_loading.load_data import load_pair\n",
    "\n",
    "def eval_feedbacks(feedbacks, env_name, unlabel_pair=\"unlabel-100000\"):\n",
    "    unlabel_pairs = load_pair(\n",
    "        env_name=env_name,\n",
    "        exp_name=\"CUDA-01-00\",\n",
    "        pair_type=\"train\",\n",
    "        pair_algo=unlabel_pair,\n",
    "    )\n",
    "\n",
    "    dataset = load_dataset(env_name=env_name)\n",
    "    cumsum = np.cumsum(dataset[\"rewards\"], dtype=np.float64)\n",
    "\n",
    "    raw_traj_truth_rewards = []\n",
    "    for p in unlabel_pairs:\n",
    "        (s0, e0), (s1, e1), _ = p\n",
    "        raw_traj_truth_rewards.append(get_total_reward(s0, e0, cumsum))\n",
    "        raw_traj_truth_rewards.append(get_total_reward(s1, e1, cumsum))\n",
    "\n",
    "    traj_truth_rewards = []\n",
    "    total = correct = 0\n",
    "    for (s0, e0), (s1, e1), mu in feedbacks:\n",
    "        r0 = get_total_reward(s0, e0, cumsum)\n",
    "        r1 = get_total_reward(s1, e1, cumsum)\n",
    "        if mu != 0.5:\n",
    "            total += 1\n",
    "            if (mu == 1.0 and r0 < r1) or (mu == 0.0 and r0 > r1):\n",
    "                correct += 1\n",
    "        traj_truth_rewards.extend([(r0, r1), (r1, r0)])\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "\n",
    "    bins = 25\n",
    "    bin_edges = np.linspace(0, 250, bins + 1)\n",
    "    r0_list = [r0 for r0, _ in traj_truth_rewards]\n",
    "    r1_list = [r1 for _, r1 in traj_truth_rewards]\n",
    "    observed, _, _ = np.histogram2d(r0_list, r1_list, bins=[bin_edges, bin_edges])\n",
    "    observed = observed.T\n",
    "\n",
    "    traj_hist, _ = np.histogram(raw_traj_truth_rewards, bins=bin_edges)\n",
    "    traj_prob = traj_hist / np.sum(traj_hist)\n",
    "    expected = np.outer(traj_prob, traj_prob) * np.sum(observed)\n",
    "\n",
    "    eps = 1e-8\n",
    "    P = observed / (np.sum(observed) + eps)\n",
    "    Q = expected / (np.sum(expected) + eps)\n",
    "    mask = P > 0\n",
    "    kl_divergence = np.sum(P[mask] * np.log(P[mask] / (Q[mask] + eps)))\n",
    "\n",
    "    return kl_divergence, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f91b208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def extract_feedbacks_without_buckets(\n",
    "    env_name,\n",
    "    exp_name,\n",
    "    result,\n",
    "    label_pair_algo=\"ternary-500\",\n",
    "    unlabel_pair_algo=\"unlabel-100000\",\n",
    "    new_pair_name=\"aug-bucket\",\n",
    "    n=10000,\n",
    "    m=10000,\n",
    "    z=3.1,\n",
    "    threshold=0.99,\n",
    "    use_conf=False,\n",
    "):\n",
    "    unlabeled_feedbacks = load_pair(\n",
    "        env_name=env_name,\n",
    "        exp_name=exp_name,\n",
    "        pair_type=\"train\",\n",
    "        pair_algo=unlabel_pair_algo,\n",
    "    )\n",
    "\n",
    "    data = np.array(result)\n",
    "    mean = data[:, 1]\n",
    "    std = data[:, 2]\n",
    "    var = std**2\n",
    "    mean_cum = np.cumsum(mean, dtype=np.float64)\n",
    "    var_cum = np.cumsum(var, dtype=np.float64)\n",
    "\n",
    "    # trajectory list 생성\n",
    "    trajectories = []\n",
    "    for p in unlabeled_feedbacks:\n",
    "        trajectories.append(p[0])\n",
    "        trajectories.append(p[1])\n",
    "    trajectories = trajectories[:n]\n",
    "\n",
    "    traj_data = []\n",
    "    for s, e in trajectories:\n",
    "        r = get_total_reward(s, e, mean_cum)\n",
    "        v = get_total_reward(s, e, var_cum)\n",
    "        std_ = np.sqrt(v)\n",
    "        traj_data.append(((s, e), r, std_))\n",
    "\n",
    "    seen_pairs = set()\n",
    "    feedbacks = []\n",
    "    total = len(traj_data)\n",
    "\n",
    "    pbar = tqdm(total=m, desc=\"Sampling confident feedbacks\")\n",
    "    while len(feedbacks) < m:\n",
    "        i, j = random.sample(range(total), 2)\n",
    "        if i == j:\n",
    "            continue\n",
    "\n",
    "        pair_key = (min(i, j), max(i, j))\n",
    "        if pair_key in seen_pairs:\n",
    "            continue\n",
    "        seen_pairs.add(pair_key)\n",
    "\n",
    "        t0 = traj_data[i]\n",
    "        t1 = traj_data[j]\n",
    "\n",
    "        if t0[1] > t1[1]:\n",
    "            t0, t1 = t1, t0\n",
    "        \n",
    "        (s0, r0, std0) = t0\n",
    "        (s1, r1, std1) = t1\n",
    "\n",
    "        if use_conf:\n",
    "            mu = sigmoid(r1 - r0)\n",
    "            if mu > threshold:\n",
    "                feedbacks.append((s0, s1, 1.0))\n",
    "                pbar.update(1)\n",
    "            elif 1 - mu > threshold:\n",
    "                feedbacks.append((s0, s1, 0.0))\n",
    "                pbar.update(1)\n",
    "        else:\n",
    "            upper_0 = r0 + z * std0\n",
    "            lower_1 = r1 - z * std1\n",
    "\n",
    "            if upper_0 < lower_1:\n",
    "                feedbacks.append((s0, s1, 1.0))\n",
    "                pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    return feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1522c471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_dim: 39 act_dim: 4\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-00/reward/ternary-500/MR-exp_00.pth\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-00/reward/ternary-500/MR-exp_02.pth\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-00/reward/ternary-500/MR-exp_01.pth\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-00/reward/ternary-500/MR-exp_06.pth\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-00/reward/ternary-500/MR-exp_03.pth\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-00/reward/ternary-500/MR-exp_05.pth\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-00/reward/ternary-500/MR-exp_04.pth\n",
      "obs_dim: 39 act_dim: 4\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-01/reward/ternary-500/MR-exp_00.pth\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-01/reward/ternary-500/MR-exp_02.pth\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-01/reward/ternary-500/MR-exp_01.pth\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-01/reward/ternary-500/MR-exp_06.pth\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-01/reward/ternary-500/MR-exp_03.pth\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-01/reward/ternary-500/MR-exp_05.pth\n",
      "Model loaded from model/button-press-topdown-v2/CUDA-01-01/reward/ternary-500/MR-exp_04.pth\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "z_list = [1.0, 1.25, 1.5, 1.75, 2.0, 2.25, 2.5, 2.75, 3.0, 4.0, 4.5, 5.0, 7.0, 8.5, 10.0, 12.5, 15.0, 17.5, 20.0]\n",
    "mu_list = [0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.975, 0.99, 0.999, 0.9999, 0.99999]\n",
    "\n",
    "results = []\n",
    "\n",
    "csv_path = \"feedback_eval_results.csv\"\n",
    "\n",
    "# 헤더가 없을 경우 생성\n",
    "if not os.path.exists(csv_path):\n",
    "    with open(csv_path, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"env\", \"is_z\", \"z\", \"kl\", \"acc\"])\n",
    "\n",
    "for env in env_list:\n",
    "    result_list = []\n",
    "    for i in range(10):\n",
    "        exp_name = f\"CUDA-01-{i:02d}\"\n",
    "        result = predict_rewards(\n",
    "            env, exp_name, pair_algo=\"ternary-500\", reward_model_algo=\"MR-exp\"\n",
    "        )\n",
    "        result_list.append(result)\n",
    "\n",
    "    for z in z_list:\n",
    "        feedbacks = []\n",
    "        for i in range(10):\n",
    "            exp_name = f\"CUDA-01-{i:02d}\"\n",
    "            feedback = extract_feedbacks_without_buckets(\n",
    "                env_name=env,\n",
    "                exp_name=exp_name,\n",
    "                result=result_list[i],\n",
    "                label_pair_algo=\"ternary-500\",\n",
    "                unlabel_pair_algo=\"unlabel-100000\",\n",
    "                new_pair_name=\"aug-bucket\",\n",
    "                n=10000,\n",
    "                m=10000,\n",
    "                z=z,\n",
    "                threshold=0.999,\n",
    "                use_conf=False,\n",
    "            )\n",
    "            feedbacks.extend(feedback)\n",
    "\n",
    "        kl, acc = eval_feedbacks(feedbacks, env_name=env, unlabel_pair=\"unlabel-100000\")\n",
    "\n",
    "        with open(csv_path, mode='a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([env, True, z, round(kl, 4), round(acc, 4)])\n",
    "\n",
    "        print(f\"Env: {env}, Z: {z}, KL: {kl:.4f}, Acc: {acc:.4f}\")\n",
    "    \n",
    "    for mu in mu_list:\n",
    "        feedbacks = []\n",
    "        for i in range(10):\n",
    "            exp_name = f\"CUDA-01-{i:02d}\"\n",
    "            feedback = extract_feedbacks_without_buckets(\n",
    "                env_name=env,\n",
    "                exp_name=exp_name,\n",
    "                result=result_list[i],\n",
    "                label_pair_algo=\"ternary-500\",\n",
    "                unlabel_pair_algo=\"unlabel-100000\",\n",
    "                new_pair_name=\"aug-bucket\",\n",
    "                n=10000,\n",
    "                m=10000,\n",
    "                z=3.1,\n",
    "                threshold=mu,\n",
    "                use_conf=True,\n",
    "            )\n",
    "            feedbacks.extend(feedback)\n",
    "\n",
    "        kl, acc = eval_feedbacks(feedbacks, env_name=env, unlabel_pair=\"unlabel-100000\")\n",
    "\n",
    "        with open(csv_path, mode='a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([env, False, mu, round(kl, 4), round(acc, 4)])\n",
    "\n",
    "        print(f\"Env: {env}, Mu: {mu}, KL: {kl:.4f}, Acc: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ff070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lockcept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
