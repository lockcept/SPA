{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55185993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"src\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c489f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# env_name = \"button-press-topdown-v2\"\n",
    "# env_name = \"box-close-v2\"\n",
    "env_name = \"dial-turn-v2\"\n",
    "exp_name = \"AESPA-22-test\"\n",
    "pair_algo = \"ternary-500\"\n",
    "reward_model_algo = \"MR-exp\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\" \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TRAJECTORY_LENGTH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4eff66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading.load_data import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\n",
    "    env_name=env_name,\n",
    ")\n",
    "cumsum = np.cumsum(dataset[\"rewards\"], dtype=np.float64)\n",
    "average_reward = np.mean(dataset[\"rewards\"])\n",
    "\n",
    "\n",
    "def get_reward_from_cumsum(start, end):\n",
    "    \"\"\"\n",
    "    Get the reward from the cumulative sum between start and end indices.\n",
    "    \"\"\"\n",
    "\n",
    "    if start == 0:\n",
    "        return cumsum[end - 1]\n",
    "    else:\n",
    "        return cumsum[end - 1] - cumsum[start - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ebdd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "from data_loading.load_data import load_pair\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def augment_with_bucket(env_name, exp_name, result, k=20, select_ratio=0.005, z=10):\n",
    "    \"\"\"\n",
    "    각 bucket에서 uncertainty 가장 낮은 top N% trajectory 선택 후,\n",
    "             모든 bucket 쌍에 대해 pair 생성\n",
    "    각 bucket 쌍에서 신뢰구간 겹치지 않는 pair를 top_k 개 만큼 생성\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------- 1. 기본 정보 세팅 (trajectory 정리) -----------\n",
    "    data = np.array(result)\n",
    "    mean = data[:, 1]\n",
    "    std = data[:, 2]\n",
    "    var = std**2\n",
    "    mean_cum = np.cumsum(mean, dtype=np.float64)\n",
    "    var_cum = np.cumsum(var, dtype=np.float64)\n",
    "\n",
    "    feedbacks = load_pair(\n",
    "        env_name=env_name,\n",
    "        exp_name=exp_name,\n",
    "        pair_type=\"train\",\n",
    "        pair_algo=\"ternary-10000\",\n",
    "    )\n",
    "    trajectories = []\n",
    "\n",
    "    for p in feedbacks:\n",
    "        trajectories.append(p[0])\n",
    "        trajectories.append(p[1])\n",
    "\n",
    "    trajs = []\n",
    "    for (s, e) in trajectories:\n",
    "        r = mean_cum[e - 1] - (mean_cum[s - 1] if s > 0 else 0)\n",
    "        v = var_cum[e - 1] - (var_cum[s - 1] if s > 0 else 0)\n",
    "        std_ = np.sqrt(v)\n",
    "        trajs.append(((s, e), r, std_))\n",
    "\n",
    "    # ----------- 2. 버킷 나누기 -----------\n",
    "    trajs.sort(key=lambda x: x[1])  # reward 기준 정렬\n",
    "    n = len(trajs)\n",
    "    buckets = [trajs[n * i // k : n * (i + 1) // k] for i in range(k)]\n",
    "    bucket_ranges = [(buckets[i][0][1], buckets[i][-1][1]) for i in range(k)]\n",
    "\n",
    "    for i, bucket_range in enumerate(bucket_ranges):\n",
    "        print(f\"Bucket {i}: Range = {bucket_range[0]:.2f} to {bucket_range[1]:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ----------- 3. Step 3: std 기준 top N% 선택 후 전체 조합 -----------\n",
    "    feedbacks_bucket_1 = []\n",
    "\n",
    "    # 각 bucket에서 select_ratio 비율만큼 선택\n",
    "    selected_per_bucket = []\n",
    "    for bucket in buckets:\n",
    "        num_select = max(1, int(len(bucket) * select_ratio))\n",
    "        sorted_by_std = sorted(bucket, key=lambda x: x[2])\n",
    "        selected_per_bucket.append(sorted_by_std[:num_select])\n",
    "\n",
    "    success_rate_i_j = []\n",
    "\n",
    "    # 모든 bucket 쌍 조합에 대해 pair 생성 및 정답률 계산\n",
    "    for i, j in itertools.combinations(range(k), 2):\n",
    "        if (np.abs(i - j ) < 3): \n",
    "            continue\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for traj_i, traj_j in itertools.product(selected_per_bucket[i], selected_per_bucket[j]):\n",
    "            s0, r0, _ = traj_i\n",
    "            s1, r1, _ = traj_j\n",
    "            feedbacks_bucket_1.append((s0, s1, 1.0))\n",
    "\n",
    "            rewards_sum_0 = get_reward_from_cumsum(s0[0], s0[1])\n",
    "            rewards_sum_1 = get_reward_from_cumsum(s1[0], s1[1])\n",
    "\n",
    "            mu_value = np.where(\n",
    "                np.abs(rewards_sum_0 - rewards_sum_1) < average_reward * 0.0 * 25,\n",
    "                0.5,\n",
    "                np.where(rewards_sum_0 > rewards_sum_1, 0, 1),\n",
    "            )\n",
    "            predicted = 1.0  \n",
    "\n",
    "            if predicted == mu_value:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "        acc = correct / total if total > 0 else 0.0\n",
    "        success_rate_i_j.append((i, j, acc))\n",
    "\n",
    "\n",
    "    print(f\"[bucket_1] Generated {len(feedbacks_bucket_1)} confident pairs\")\n",
    "\n",
    "   # heatmap matrix 만들기\n",
    "    heat = np.full((k, k), np.nan)\n",
    "    for i, j, acc in success_rate_i_j:\n",
    "        heat[i, j] = acc\n",
    "\n",
    "    # 전체 정답률 평균 계산\n",
    "    all_accs = [acc for _, _, acc in success_rate_i_j]\n",
    "    overall_accuracy = sum(all_accs) / len(all_accs) if all_accs else 0.0\n",
    "    print(f\"Overall Pairwise Accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    "    # heatmap 시각화\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(heat, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", cbar=True,\n",
    "                xticklabels=range(k), yticklabels=range(k), annot_kws={\"size\": 4})\n",
    "    plt.title(\"Pairwise Accuracy Heatmap\")\n",
    "    plt.xlabel(\"Bucket j\")\n",
    "    plt.ylabel(\"Bucket i\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # conf 로 구한 pair들의 분포 그리기\n",
    "    unlabel_feedbacks = load_pair(\n",
    "        env_name=env_name,\n",
    "        exp_name=exp_name,\n",
    "        pair_type=\"train\",\n",
    "        pair_algo=\"ternary-10000\",\n",
    "    )\n",
    "\n",
    "    conf_pairs = []\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    threshold = 0.999\n",
    "\n",
    "    for p in tqdm(unlabel_feedbacks, desc=\"Filtering pairs using uncertainty\"):\n",
    "        (s0, e0), (s1, e1), _ = p\n",
    "\n",
    "        # 예측 reward 합\n",
    "        r0 = mean_cum[e0 - 1] - (mean_cum[s0 - 1] if s0 > 0 else 0)\n",
    "        r1 = mean_cum[e1 - 1] - (mean_cum[s1 - 1] if s1 > 0 else 0)\n",
    "\n",
    "        mu = sigmoid(r1 - r0)\n",
    "\n",
    "        # mu가 threshold 이상인 경우만 confident_pairs에 추가\n",
    "        if mu > threshold or mu < 1 - threshold:\n",
    "            conf_pairs.append(((s0,e0), (s1,e1)))\n",
    "        \n",
    "\n",
    "    def get_total_reward(s, e, reward_cumsum):\n",
    "        return reward_cumsum[e - 1] - (reward_cumsum[s - 1] if s > 0 else 0)\n",
    "\n",
    "    def get_bucket_index(reward, bucket_ranges):\n",
    "        for i, (low, high) in enumerate(bucket_ranges):\n",
    "            if low <= reward <= high:  # high 포함 or 미포함은 상황 따라 조정\n",
    "                return i\n",
    "        return None  # 혹시라도 범위를 벗어나는 경우\n",
    "    \n",
    "    bucket_matrix = np.zeros((k, k), dtype=int)\n",
    "\n",
    "    # bucket_pairs = [(i, j) for i, j, _ in feedbacks_bucket_1]\n",
    "\n",
    "    for (s0, e0), (s1, e1) in conf_pairs:\n",
    "        r0 = get_total_reward(s0, e0, mean_cum)\n",
    "        r1 = get_total_reward(s1, e1, mean_cum)\n",
    "\n",
    "        b0 = get_bucket_index(r0, bucket_ranges)\n",
    "        b1 = get_bucket_index(r1, bucket_ranges)\n",
    "\n",
    "        if b0 is not None and b1 is not None:\n",
    "            bucket_matrix[b0, b1] += 1\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(bucket_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[f\"B{j}\" for j in range(k)],\n",
    "                yticklabels=[f\"B{i}\" for i in range(k)])\n",
    "    plt.xlabel(\"Bucket j (r1)\")\n",
    "    plt.ylabel(\"Bucket i (r0)\")\n",
    "    plt.title(\"Confident Pair Distribution across Buckets\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e12e3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reward_learning.train_model import train_reward_model\n",
    "\n",
    "\n",
    "def train_mr(env_name, exp_name):\n",
    "    for i in range(7):\n",
    "        train_reward_model(\n",
    "            env_name=env_name,\n",
    "            exp_name=exp_name,\n",
    "            pair_algo=\"ternary-500\",\n",
    "            reward_model_algo=\"MR-exp\",\n",
    "            reward_model_tag=f\"{i:02d}\",\n",
    "            num_epoch=200,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d4d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation.data_research import calculate_from_mr, train_mr_and_surf\n",
    "\n",
    "\n",
    "def main():\n",
    "    # train_mr(env_name, exp_name)\n",
    "    result = calculate_from_mr(env_name, exp_name)\n",
    "    augment_with_bucket(\n",
    "        env_name=env_name,\n",
    "        exp_name=exp_name,\n",
    "        result=result,\n",
    "        k=20,\n",
    "        select_ratio=0.01,\n",
    "        z=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae6c291f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Pair file not found at pair/dial-turn-v2/AESPA-22-test/train/ternary-10000.npz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# train_mr(env_name, exp_name)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     result \u001b[38;5;241m=\u001b[39m calculate_from_mr(env_name, exp_name)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43maugment_with_bucket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mselect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m, in \u001b[0;36maugment_with_bucket\u001b[0;34m(env_name, exp_name, result, k, select_ratio, z)\u001b[0m\n\u001b[1;32m     21\u001b[0m mean_cum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(mean, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m     22\u001b[0m var_cum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(var, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m---> 24\u001b[0m feedbacks \u001b[38;5;241m=\u001b[39m \u001b[43mload_pair\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpair_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpair_algo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mternary-10000\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m trajectories \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m feedbacks:\n",
      "File \u001b[0;32m~/jaewook/SPA/src/data_loading/load_data.py:350\u001b[0m, in \u001b[0;36mload_pair\u001b[0;34m(env_name, exp_name, pair_type, pair_algo)\u001b[0m\n\u001b[1;32m    345\u001b[0m path \u001b[38;5;241m=\u001b[39m get_pair_path(\n\u001b[1;32m    346\u001b[0m     env_name\u001b[38;5;241m=\u001b[39menv_name, exp_name\u001b[38;5;241m=\u001b[39mexp_name, pair_type\u001b[38;5;241m=\u001b[39mpair_type, pair_algo\u001b[38;5;241m=\u001b[39mpair_algo\n\u001b[1;32m    347\u001b[0m )\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPair file not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    352\u001b[0m pair \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pair[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Pair file not found at pair/dial-turn-v2/AESPA-22-test/train/ternary-10000.npz"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f393756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lockcept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
