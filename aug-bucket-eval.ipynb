{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55185993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"src\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c489f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "env_name = \"button-press-topdown-v2\"\n",
    "# env_name = \"box-close-v2\"\n",
    "# env_name = \"dial-turn-v2\"\n",
    "# env_name = \"sweep-v2\"\n",
    "exp_name = \"AESPA-22-00\"\n",
    "pair_algo = \"ternary-500\"\n",
    "# reward_model_algo = \"MR-exp\"\n",
    "reward_model_algo = \"MR-linear\"\n",
    "test_pair_algo = \"ternary-500-aug-bucket-knn\"\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\" \n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "TRAJECTORY_LENGTH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52e5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation.data_research import predict_rewards\n",
    "from data_loading.load_data import load_dataset\n",
    "\n",
    "\n",
    "def predict_only_rewards(\n",
    "    env_name,\n",
    "    exp_name,\n",
    "    pair_algo,\n",
    "    reward_model_algo,\n",
    "):\n",
    "    result = predict_rewards(\n",
    "        env_name=env_name,\n",
    "        exp_name=exp_name,\n",
    "        pair_algo=pair_algo,\n",
    "        reward_model_algo=reward_model_algo,\n",
    "    )\n",
    "\n",
    "    pred_reward_list = [r for (_, r, _, _) in result]\n",
    "    pred_reward_list = np.array(pred_reward_list)\n",
    "\n",
    "    return pred_reward_list\n",
    "\n",
    "# True reward\n",
    "dataset = load_dataset(\n",
    "    env_name=env_name,\n",
    ")\n",
    "cumsum = np.cumsum(dataset[\"rewards\"], dtype=np.float64)\n",
    "average_reward = np.mean(dataset[\"rewards\"])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def get_reward_from_cumsum(start, end):\n",
    "    \"\"\"\n",
    "    Get the reward from the cumulative sum between start and end indices.\n",
    "    \"\"\"\n",
    "\n",
    "    if start == 0:\n",
    "        return cumsum[end - 1]\n",
    "    else:\n",
    "        return cumsum[end - 1] - cumsum[start - 1]\n",
    "\n",
    "def get_total_reward(s, e, reward_cumsum):\n",
    "    return reward_cumsum[e - 1] - (reward_cumsum[s - 1] if s > 0 else 0)\n",
    "\n",
    "def get_bucket_index(reward, bucket_ranges):\n",
    "    for i, (low, high) in enumerate(bucket_ranges):\n",
    "        if low <= reward <= high:  \n",
    "            return i\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_loading.load_data import load_pair\n",
    "\n",
    "\n",
    "def eval_feedbacks(feedbacks, test_pair_algo=\"default\", unlabel_pair=\"unlabel-100000\"):\n",
    "    traj_truth_rewards = []\n",
    "    unlabel_pairs = load_pair(\n",
    "        env_name=env_name,\n",
    "        exp_name=exp_name,\n",
    "        pair_type=\"train\",\n",
    "        pair_algo=unlabel_pair,\n",
    "    )\n",
    "    raw_traj_truth_rewards = []\n",
    "    for p in unlabel_pairs:\n",
    "        (s0, e0), (s1, e1), _ = p\n",
    "        raw_traj_truth_rewards.append(\n",
    "            get_reward_from_cumsum(s0, e0)\n",
    "        )\n",
    "        raw_traj_truth_rewards.append(\n",
    "            get_reward_from_cumsum(s1, e1)\n",
    "        )\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for p in feedbacks:\n",
    "        (s0, e0), (s1, e1), mu = p\n",
    "\n",
    "        r0 = get_reward_from_cumsum(s0, e0)\n",
    "        r1 = get_reward_from_cumsum(s1, e1)\n",
    "\n",
    "        if mu != 0.5:\n",
    "            total += 1\n",
    "        if mu == 1.0 and r0 < r1:\n",
    "            correct += 1\n",
    "        elif mu == 0.0 and r0 > r1:\n",
    "            correct += 1\n",
    "\n",
    "        traj_truth_rewards.append((r0, r1))\n",
    "        traj_truth_rewards.append((r1, r0))\n",
    "\n",
    "    print(f\"Total: {total}, Correct: {correct}, Accuracy: {correct / total:.4f}\")\n",
    "\n",
    "    # 히스토그램 설정\n",
    "    bins = 25\n",
    "    range_ = [[0, 250], [0, 250]]\n",
    "    bin_edges = np.linspace(0, 250, bins + 1)\n",
    "\n",
    "    # feedback pairs (r0, r1)\n",
    "    r0_list = [r0 for r0, _ in traj_truth_rewards]\n",
    "    r1_list = [r1 for _, r1 in traj_truth_rewards]\n",
    "\n",
    "    # 관측된 joint histogram\n",
    "    observed, _, _ = np.histogram2d(r0_list, r1_list, bins=[bin_edges, bin_edges])\n",
    "    observed = observed.T  # display를 위해 transpose\n",
    "\n",
    "    # traj_reward_list 기반으로 marginal 분포 추정\n",
    "    traj_hist, _ = np.histogram(raw_traj_truth_rewards, bins=bin_edges)\n",
    "    traj_prob = traj_hist / np.sum(traj_hist)  # 확률 분포로 정규화\n",
    "\n",
    "    # 독립 가정 하 joint 분포 계산\n",
    "    expected = np.outer(traj_prob, traj_prob) * np.sum(observed)\n",
    "\n",
    "    # 관측 / 기대 비율\n",
    "    ratio = observed / (expected + 1e-8)\n",
    "\n",
    "    # 감마 조정\n",
    "    gamma = 0.3\n",
    "    adjusted_ratio = np.power(ratio, gamma)\n",
    "\n",
    "    # 시각화\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    im = plt.imshow(\n",
    "        adjusted_ratio, origin=\"lower\", aspect=\"equal\",\n",
    "        extent=[0, 250, 0, 250], cmap=\"Blues\", vmin=0.0, vmax=2.0\n",
    "    )\n",
    "    plt.colorbar(im, label=\"Observed / Expected Ratio\")\n",
    "    plt.xlabel(\"Reward 0\")\n",
    "    plt.ylabel(\"Reward 1\")\n",
    "    plt.title(f\"Reward Pair Density Ratio (Obs / Exp) under Independence ({test_pair_algo})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "\n",
    "def draw_bucket_distribution(bucketwise_rewards, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    k = len(bucketwise_rewards)\n",
    "    for b in range(k):\n",
    "        rewards = bucketwise_rewards[b]\n",
    "        if rewards:\n",
    "            # KDE 곡선\n",
    "            sns.kdeplot(rewards, label=f\"Bucket {b}\", linewidth=1)\n",
    "\n",
    "            # 평균값\n",
    "            mean_val = np.mean(rewards)\n",
    "            max_density = sns.kdeplot(rewards).get_lines()[-1].get_data()[1].max()\n",
    "\n",
    "            # 텍스트 위치: (x=mean, y=곡선 최고점 근처 또는 적당한 위치)\n",
    "            plt.text(mean_val, max_density * 1.05, f\"B{b}\\nμ={mean_val:.2f}\",\n",
    "                    ha='center', va='bottom', fontsize=8, color='black')\n",
    "\n",
    "    plt.xlabel(\"Trajectory Reward\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(f\"Reward Distribution by Bucket ({title})\")\n",
    "    plt.legend(fontsize=8, ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(18, 10), sharex=True, sharey=True)\n",
    "\n",
    "    for b in range(k):\n",
    "        ax = axes[b // 5][b % 5]\n",
    "        rewards = bucketwise_rewards[b]\n",
    "        if rewards:\n",
    "            ax.hist(rewards, bins=30, color='skyblue', edgecolor='black')\n",
    "            ax.set_title(f\"Bucket {b}\\nμ={np.mean(rewards):.2f}\")\n",
    "        else:\n",
    "            ax.set_title(f\"Bucket {b} (empty)\")\n",
    "\n",
    "    plt.suptitle(f\"Bucket-wise Reward Histogram ({title})\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "def eval_buckets(\n",
    "    env_name, \n",
    "    exp_name, \n",
    "    buckets, \n",
    "    result,\n",
    "    feedbacks = None,\n",
    "    aug_pair_algo = None,\n",
    "):\n",
    "    data = np.array(result)\n",
    "    mean = data[:, 1]\n",
    "    std = data[:, 2]\n",
    "    var = std**2\n",
    "    mean_cum = np.cumsum(mean, dtype=np.float64)\n",
    "    var_cum = np.cumsum(var, dtype=np.float64)\n",
    "\n",
    "    # 1. buckets 별 분포 그리기\n",
    "    k = len(buckets)\n",
    "    for i in range(k):\n",
    "        buckets[i] = sorted(buckets[i], key=lambda x: x[1])\n",
    "    bucket_ranges = [(buckets[i][0][1], buckets[i][-1][1]) for i in range(k)]\n",
    "\n",
    "    for i, bucket_range in enumerate(bucket_ranges):\n",
    "        print(f\"Bucket {i} ({len(buckets[i])}): Range = {bucket_range[0]:.2f} to {bucket_range[1]:.2f}\")\n",
    "\n",
    "    bucket_trajectories = set()\n",
    "    for i in range(k):\n",
    "        for j in range(len(buckets[i])):\n",
    "            s, e = buckets[i][j][0]\n",
    "            bucket_trajectories.add((s, e))\n",
    "    \n",
    "    bucket_trajectories = list(bucket_trajectories)\n",
    "    print(f\"Total {len(bucket_trajectories)} train trajectories\")\n",
    "\n",
    "    bucketwise_rewards_train = [[] for _ in range(k)]\n",
    "    for s, e in bucket_trajectories:\n",
    "        r_bucket = get_total_reward(s, e, mean_cum)\n",
    "        r_dist = get_total_reward(s, e, mean_cum)\n",
    "\n",
    "        b = get_bucket_index(r_bucket, bucket_ranges)\n",
    "        if b is not None:\n",
    "            bucketwise_rewards_train[b].append(r_dist)\n",
    "\n",
    "    draw_bucket_distribution(bucketwise_rewards_train, title=\"Predicted Reward\")\n",
    "    \n",
    "    # 2. bucket 별 true reward 분포 그리기\n",
    "    bucketwise_rewards = [[] for _ in range(k)]\n",
    "    for s, e in bucket_trajectories:\n",
    "        r_bucket = get_total_reward(s, e, mean_cum)\n",
    "        r_dist = get_total_reward(s, e, cumsum)\n",
    "\n",
    "        b = get_bucket_index(r_bucket, bucket_ranges)\n",
    "        if b is not None:\n",
    "            bucketwise_rewards[b].append(r_dist)\n",
    "    draw_bucket_distribution(bucketwise_rewards, title=\"True Reward\")\n",
    "\n",
    "    # 3. 각 bucket pair에 대해서 개수, 정답률 분포 그리기\n",
    "    if feedbacks is not None:\n",
    "        print(f\"Number of feedbacks: {len(feedbacks)}\")\n",
    "        bucket_dict = defaultdict(list)\n",
    "        bucket_matrix = np.zeros((k, k), dtype=int)\n",
    "\n",
    "        for (s0, e0), (s1, e1), _ in feedbacks:\n",
    "            # 예측 reward로 bucket 인덱스 추정\n",
    "            r0 = get_total_reward(s0, e0, mean_cum)\n",
    "            r1 = get_total_reward(s1, e1, mean_cum)\n",
    "            b0 = get_bucket_index(r0, bucket_ranges)\n",
    "            b1 = get_bucket_index(r1, bucket_ranges)\n",
    "\n",
    "            if b0 is None or b1 is None or b0 == b1:\n",
    "                continue\n",
    "\n",
    "            pred_mu = 1.0 if b1 > b0 else 0.0 if b1 < b0 else 0.5\n",
    "\n",
    "            # 실제 reward로 정답 여부 확인\n",
    "            real_r0 = get_reward_from_cumsum(s0, e0)\n",
    "            real_r1 = get_reward_from_cumsum(s1, e1)\n",
    "            real_mu = 1.0 if real_r1 > real_r0 else 0.0 if real_r1 < real_r0 else 0.5\n",
    "\n",
    "            correct = int(pred_mu == real_mu)\n",
    "\n",
    "            # 버킷 정렬 및 기록\n",
    "            i, j = sorted([b0, b1])\n",
    "            bucket_dict[(i, j)].append(correct)\n",
    "            bucket_matrix[i, j] += 1\n",
    "\n",
    "        # 정확도 계산\n",
    "        heat = np.full((k, k), np.nan)\n",
    "        success_rate_i_j = []\n",
    "\n",
    "        for (i, j), results in bucket_dict.items():\n",
    "            acc = np.mean(results)\n",
    "            heat[i, j] = acc\n",
    "            success_rate_i_j.append((i, j, acc))\n",
    "\n",
    "        # 전체 평균 정확도 출력\n",
    "        all_accs = [acc for _, _, acc in success_rate_i_j]\n",
    "        overall_accuracy = np.mean(all_accs) if all_accs else 0.0\n",
    "        print(f\"Overall Pairwise Accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    "        # 정확도 히트맵\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.heatmap(heat, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", cbar=True,\n",
    "                    xticklabels=range(k), yticklabels=range(k), annot_kws={\"size\": 4})\n",
    "        plt.title(\"Pairwise Accuracy Heatmap\")\n",
    "        plt.xlabel(\"Bucket j\")\n",
    "        plt.ylabel(\"Bucket i\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 분포 히트맵\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(bucket_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[f\"B{j}\" for j in range(k)],\n",
    "                    yticklabels=[f\"B{i}\" for i in range(k)])\n",
    "        plt.xlabel(\"Bucket j (r1)\")\n",
    "        plt.ylabel(\"Bucket i (r0)\")\n",
    "        plt.title(\"Confident Pair Distribution across Buckets\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 4. bucket 별 aug_pair_algo로 학습된 reward model로 예측한 reward 분포 그리기\n",
    "    if aug_pair_algo is not None:\n",
    "        aug_predicted_rewards = predict_only_rewards(\n",
    "            env_name=env_name,\n",
    "            exp_name=exp_name,\n",
    "            pair_algo=aug_pair_algo,\n",
    "            reward_model_algo=\"MR-linear\",\n",
    "        )\n",
    "        aug_predicted_rewards_cumsum = np.cumsum(aug_predicted_rewards, dtype=np.float64)\n",
    "\n",
    "        \n",
    "        bucketwise_rewards = [[] for _ in range(k)]\n",
    "        for s, e in bucket_trajectories:\n",
    "            r_bucket = get_total_reward(s, e, mean_cum)\n",
    "            r_dist = get_total_reward(s, e, aug_predicted_rewards_cumsum)\n",
    "\n",
    "            b = get_bucket_index(r_bucket, bucket_ranges)\n",
    "            if b is not None:\n",
    "                bucketwise_rewards[b].append(r_dist)\n",
    "        draw_bucket_distribution(bucketwise_rewards, title=\"Augmented Predicted Reward\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d4d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation.data_research import divide_into_buckets\n",
    "from data_loading.load_data import load_pair\n",
    "\n",
    "\n",
    "def main():\n",
    "    feedbacks = load_pair(\n",
    "        env_name=env_name,\n",
    "        exp_name=exp_name,\n",
    "        pair_type=\"train\",\n",
    "        pair_algo=test_pair_algo,\n",
    "    )\n",
    "\n",
    "    eval_feedbacks(feedbacks, test_pair_algo=test_pair_algo)\n",
    "\n",
    "    # result = predict_rewards(\n",
    "    #     env_name=env_name,\n",
    "    #     exp_name=exp_name,\n",
    "    #     pair_algo=\"ternary-500\",\n",
    "    #     reward_model_algo=\"MR-exp\",\n",
    "    # )\n",
    "\n",
    "    # buckets = divide_into_buckets(\n",
    "    #     env_name=env_name,\n",
    "    #     exp_name=exp_name,\n",
    "    #     result=result,\n",
    "    #     unlabel_pair_algo=\"unlabel-100000\",\n",
    "    #     min_k=10,\n",
    "    #     max_k=20,\n",
    "    #     use_knn=False,\n",
    "    # )\n",
    "\n",
    "    # eval_buckets(\n",
    "    #     env_name=env_name,\n",
    "    #     exp_name=exp_name,\n",
    "    #     buckets=buckets,\n",
    "    #     result=result,\n",
    "    #     # feedbacks=feedbacks,\n",
    "    #     # aug_pair_algo=test_pair_algo,\n",
    "    #     feedbacks=None,\n",
    "    #     aug_pair_algo=None,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a569c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lockcept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
